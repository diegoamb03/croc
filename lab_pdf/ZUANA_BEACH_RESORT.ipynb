{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1063e3a2",
   "metadata": {},
   "source": [
    "## ZOANA BICH RESORT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f4039",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f037daea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymupdf in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (1.26.0)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (0.11.6)\n",
      "Requirement already satisfied: tabula-py in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (2.10.0)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (0.3.13)\n",
      "Requirement already satisfied: Pillow in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (11.2.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: camelot in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (12.6.29)\n",
      "Requirement already satisfied: camelot-py[cv] in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (1.0.0)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from pdfplumber) (20250327)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from pdfminer.six==20250327->pdfplumber) (45.0.3)\n",
      "Requirement already satisfied: numpy>1.24.4 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from tabula-py) (2.2.5)\n",
      "Requirement already satisfied: distro in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from tabula-py) (1.9.0)\n",
      "Requirement already satisfied: click>=8.0.1 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from camelot-py[cv]) (8.2.1)\n",
      "Requirement already satisfied: chardet>=5.1.0 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from camelot-py[cv]) (5.2.0)\n",
      "Requirement already satisfied: openpyxl>=3.1.0 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from camelot-py[cv]) (3.1.5)\n",
      "Requirement already satisfied: pypdf<6.0,>=4.0 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from camelot-py[cv]) (5.5.0)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from camelot-py[cv]) (0.9.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.7.0.68 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from camelot-py[cv]) (4.11.0.86)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: SQLAlchemy<0.8.0,>=0.7.7 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from camelot) (0.7.10)\n",
      "Requirement already satisfied: Elixir>=0.7.1 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from camelot) (0.7.1)\n",
      "Requirement already satisfied: sqlalchemy-migrate>=0.7.1 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from camelot) (0.11.0)\n",
      "Requirement already satisfied: Jinja2>=2.5.5 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from camelot) (3.1.6)\n",
      "Requirement already satisfied: xlwt==0.7.2 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from camelot) (0.7.2)\n",
      "Requirement already satisfied: xlrd==0.7.1 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from camelot) (0.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0.1->camelot-py[cv]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from Jinja2>=2.5.5->camelot) (3.0.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from openpyxl>=3.1.0->camelot-py[cv]) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pbr>=1.8 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from sqlalchemy-migrate>=0.7.1->camelot) (6.1.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from sqlalchemy-migrate>=0.7.1->camelot) (5.2.1)\n",
      "Requirement already satisfied: sqlparse in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from sqlalchemy-migrate>=0.7.1->camelot) (0.5.3)\n",
      "Requirement already satisfied: Tempita>=0.4 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from sqlalchemy-migrate>=0.7.1->camelot) (0.6.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from pbr>=1.8->sqlalchemy-migrate>=0.7.1->camelot) (80.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\analista de  datos\\appdata\\roaming\\python\\python312\\site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: camelot-py 1.0.0 does not provide the extra 'cv'\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf pdfplumber tabula-py camelot-py[cv] pytesseract Pillow pandas camelot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a5e0c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de pdf\n",
    "import fitz  \n",
    "import pdfplumber\n",
    "import tabula\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "25448e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion de limpieza de columnas : \n",
    "#funcion de limpieza de columnas : \n",
    "import unicodedata\n",
    "def limpiar_columnas(df):\n",
    "    # Convertimos los nombres de columna a string\n",
    "    df.columns = df.columns.astype(str)\n",
    "\n",
    "    # Normalizamos las tildes usando unicodedata\n",
    "    df.columns = [\n",
    "        unicodedata.normalize('NFKD', col)\n",
    "        .encode('ascii', 'ignore')\n",
    "        .decode('utf-8')\n",
    "        for col in df.columns\n",
    "    ]\n",
    "\n",
    "    # Aplicamos las transformaciones\n",
    "    df.columns = (\n",
    "        pd.Index(df.columns)\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(' ', '_')\n",
    "        .str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    )\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8829dd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando: resources/ZUANA_BEACH_RESORT.pdf\n",
      "Análisis de contenido: {'tiene_texto': True, 'tiene_imagenes': True, 'posibles_tablas': True, 'es_escaneado': False, 'calidad_texto': 'alta'}\n",
      "Extrayendo texto...\n",
      "Extrayendo tablas...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class PDFExtractorAdaptativo:\n",
    "    def __init__(self):\n",
    "        self.metodos_texto = ['pdfplumber', 'pymupdf', 'ocr']\n",
    "        self.metodos_tablas = ['tabula', 'pdfplumber']  # Quitamos 'camelot'\n",
    "    \n",
    "    def detectar_tipo_contenido(self, archivo_pdf):\n",
    "        \"\"\"Detecta qué tipo de contenido tiene el PDF\"\"\"\n",
    "        try:\n",
    "            doc = fitz.open(archivo_pdf)\n",
    "            primera_pagina = doc[0]\n",
    "            \n",
    "            texto = primera_pagina.get_text().strip()\n",
    "            imagenes = primera_pagina.get_images()\n",
    "            \n",
    "            with pdfplumber.open(archivo_pdf) as pdf:\n",
    "                page = pdf.pages[0]\n",
    "                tablas_detectadas = page.find_tables()\n",
    "            \n",
    "            resultado = {\n",
    "                'tiene_texto': len(texto) > 50,\n",
    "                'tiene_imagenes': len(imagenes) > 0,\n",
    "                'posibles_tablas': len(tablas_detectadas) > 0,\n",
    "                'es_escaneado': len(texto) < 50 and len(imagenes) > 0,\n",
    "                'calidad_texto': 'alta' if len(texto) > 200 else 'baja'\n",
    "            }\n",
    "            \n",
    "            doc.close()\n",
    "            return resultado\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def extraer_texto_robusto(self, archivo_pdf):\n",
    "        \"\"\"Extrae texto probando diferentes métodos\"\"\"\n",
    "        metodos_resultados = {}\n",
    "        \n",
    "        # pdfplumber\n",
    "        try:\n",
    "            with pdfplumber.open(archivo_pdf) as pdf:\n",
    "                texto = \"\"\n",
    "                for page in pdf.pages:\n",
    "                    texto += page.extract_text() + \"\\n\"\n",
    "                metodos_resultados['pdfplumber'] = texto\n",
    "        except Exception as e:\n",
    "            metodos_resultados['pdfplumber'] = f\"Error: {e}\"\n",
    "        \n",
    "        # pymupdf\n",
    "        try:\n",
    "            doc = fitz.open(archivo_pdf)\n",
    "            texto = \"\"\n",
    "            for page in doc:\n",
    "                texto += page.get_text() + \"\\n\"\n",
    "            doc.close()\n",
    "            metodos_resultados['pymupdf'] = texto\n",
    "        except Exception as e:\n",
    "            metodos_resultados['pymupdf'] = f\"Error: {e}\"\n",
    "        \n",
    "        # OCR\n",
    "        try:\n",
    "            doc = fitz.open(archivo_pdf)\n",
    "            texto = \"\"\n",
    "            for page_num in range(len(doc)):\n",
    "                page = doc.load_page(page_num)\n",
    "                pix = page.get_pixmap()\n",
    "                img_data = pix.tobytes(\"png\")\n",
    "                img = Image.open(io.BytesIO(img_data))\n",
    "                texto += pytesseract.image_to_string(img, lang='spa') + \"\\n\"\n",
    "            doc.close()\n",
    "            metodos_resultados['ocr'] = texto\n",
    "        except Exception as e:\n",
    "            metodos_resultados['ocr'] = f\"Error: {e}\"\n",
    "        \n",
    "        # Seleccionar mejor resultado\n",
    "        mejor_resultado = \"\"\n",
    "        max_longitud = 0\n",
    "        for metodo, resultado in metodos_resultados.items():\n",
    "            if not resultado.startswith(\"Error\") and len(resultado) > max_longitud:\n",
    "                mejor_resultado = resultado\n",
    "                max_longitud = len(resultado)\n",
    "        \n",
    "        return {\n",
    "            'texto_final': mejor_resultado,\n",
    "            'metodos_intentados': metodos_resultados,\n",
    "            'metodo_exitoso': max([k for k, v in metodos_resultados.items() \n",
    "                                 if not v.startswith(\"Error\") and len(v) == max_longitud], \n",
    "                                default=\"ninguno\")\n",
    "        }\n",
    "    \n",
    "    def extraer_tablas_robusto(self, archivo_pdf):\n",
    "        \"\"\"Extrae tablas probando diferentes métodos (sin camelot)\"\"\"\n",
    "        resultados_tablas = {}\n",
    "        \n",
    "        # tabula-py\n",
    "        try:\n",
    "            tablas = tabula.read_pdf(archivo_pdf, pages='all', multiple_tables=True)\n",
    "            resultados_tablas['tabula'] = {\n",
    "                'tablas': tablas,\n",
    "                'cantidad': len(tablas),\n",
    "                'exito': True\n",
    "            }\n",
    "        except Exception as e:\n",
    "            resultados_tablas['tabula'] = {'error': str(e), 'exito': False}\n",
    "        \n",
    "        # pdfplumber\n",
    "        try:\n",
    "            with pdfplumber.open(archivo_pdf) as pdf:\n",
    "                todas_tablas = []\n",
    "                for page in pdf.pages:\n",
    "                    tablas_pagina = page.extract_tables()\n",
    "                    for tabla in tablas_pagina:\n",
    "                        df = pd.DataFrame(tabla[1:], columns=tabla[0])\n",
    "                        todas_tablas.append(df)\n",
    "                \n",
    "                resultados_tablas['pdfplumber'] = {\n",
    "                    'tablas': todas_tablas,\n",
    "                    'cantidad': len(todas_tablas),\n",
    "                    'exito': True\n",
    "                }\n",
    "        except Exception as e:\n",
    "            resultados_tablas['pdfplumber'] = {'error': str(e), 'exito': False}\n",
    "        \n",
    "        return resultados_tablas\n",
    "    \n",
    "    def procesar_pdf_completo(self, archivo_pdf):\n",
    "        \"\"\"Proceso completo adaptativo\"\"\"\n",
    "        print(f\"Analizando: {archivo_pdf}\")\n",
    "        \n",
    "        info_contenido = self.detectar_tipo_contenido(archivo_pdf)\n",
    "        print(f\"Análisis de contenido: {info_contenido}\")\n",
    "        \n",
    "        resultado_final = {\n",
    "            'archivo': archivo_pdf,\n",
    "            'analisis_contenido': info_contenido,\n",
    "            'texto': None,\n",
    "            'tablas': None\n",
    "        }\n",
    "        \n",
    "        if info_contenido.get('tiene_texto') or info_contenido.get('es_escaneado'):\n",
    "            print(\"Extrayendo texto...\")\n",
    "            resultado_texto = self.extraer_texto_robusto(archivo_pdf)\n",
    "            resultado_final['texto'] = resultado_texto\n",
    "        \n",
    "        if info_contenido.get('posibles_tablas'):\n",
    "            print(\"Extrayendo tablas...\")\n",
    "            resultado_tablas = self.extraer_tablas_robusto(archivo_pdf)\n",
    "            resultado_final['tablas'] = resultado_tablas\n",
    "        \n",
    "        return resultado_final\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    extractor = PDFExtractorAdaptativo()\n",
    "    resultado = extractor.procesar_pdf_completo(\"resources/ZUANA_BEACH_RESORT.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7f28e261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#extraer del diccionario final tablas y texto\n",
    "textos = resultado.get('texto', {}).get('texto_final', '')\n",
    "print(type(textos))\n",
    "\n",
    "#Escritura .txt\n",
    "with open(\"ZUANA_BEACH_RESORT.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(textos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d7d62329",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_generales = {\n",
    "    \"Empresa\":                re.search(r\"^(C\\.B\\.\\s*HOTELES\\s+Y\\s+RESORTS\\s+S\\.A\\.)\", textos, re.MULTILINE).group(1),\n",
    "    \"NIT Empresa\":            re.search(r\"Nit\\.\\s*(\\d+)\", textos).group(1),\n",
    "    \"Dirección Empresa\":      re.search(r\"Dirección:\\s*(.+)\", textos).group(1),\n",
    "    \"Teléfonos Empresa\":      re.search(r\"Teléfonos:\\s*(.+)\", textos).group(1),\n",
    "    \"Fecha Impresión\":        re.search(r\"Fecha Impresión:\\s*\\n(.+)\", textos).group(1).strip(),\n",
    "    \"Hora Impresión\":         re.search(r\"Hora:\\s*(.+)\", textos).group(1).strip(),\n",
    "    \"Página\":                 re.search(r\"Página:\\s*(\\d+\\s+de\\s+\\d+)\", textos).group(1),\n",
    "    \"Fecha de creación\":      re.search(r\"Fecha de creación\\s*:\\s*([0-9/]+\\s+[0-9:APMapm]+)\", textos).group(1),\n",
    "    \"Ciudad\":                 re.search(r\"Ciudad:\\s*(.+)\", textos).group(1),\n",
    "    \"Consecutivo\":            re.search(r\"Consecutivo\\s*:\\s*(\\d+)\", textos).group(1),\n",
    "    \"Consecutivo BU\":         re.search(r\"Consecutivo BU\\s*:\\s*(\\d+)\", textos).group(1),\n",
    "    \"BU\":                     re.search(r\"BU\\s*:\\s*(.+)\", textos).group(1),\n",
    "    \"Fecha Orden\":            re.search(r\"^Fecha\\s*:\\s*([0-9/]+)\", textos, re.MULTILINE).group(1),\n",
    "    \"Fecha Entrega\":          re.search(r\"Fecha Entrega\\s*:\\s*([0-9/]+)\", textos).group(1),\n",
    "    \"Días de Plazo\":          re.search(r\"Días de Plazo\\s*:\\s*(\\d+)\", textos).group(1),\n",
    "    \"Forma de Pago\":          re.search(r\"Forma de Pago\\s*:\\s*(.+)\", textos).group(1),\n",
    "    \"Moneda\":                 re.search(r\"Moneda\\s*:\\s*(.+)\", textos).group(1),\n",
    "    \"Requisición\":            re.search(r\"Requisición\\s*:\\s*(\\d+)\", textos).group(1),\n",
    "    \"Doc/Rel\":                re.search(r\"Doc/Rel\\s*:\\s*(.+)\", textos).group(1),\n",
    "    \"Estado\":                 re.search(r\"Estado\\s*:\\s*(.+)\", textos).group(1),\n",
    "    \"Detalles\":               re.search(r\"Detalles\\s*:\\s*(.+)\", textos).group(1),\n",
    "    \"Observaciones\":          re.search(r\"Observaciones\\s*:\\s*(.+)\", textos).group(1),\n",
    "    \"Proveedor\":              re.search(r\"Proveedor\\s*:\\s*(.+)\", textos).group(1),\n",
    "    \"NIT Proveedor\":          re.search(r\"Proveedor\\s*:[\\s\\S]*?Nit\\s*:\\s*(\\d+)\", textos).group(1),\n",
    "    \"Teléfono Proveedor\":     re.search(r\"Teléfono\\s*:\\s*([0-9]+)\", textos).group(1),\n",
    "    \"Dirección Proveedor\":    re.search(r\"Dirección\\s*:\\s*(CL\\s*\\d+\\s*\\d+\\s*\\d+)\", textos).group(1),\n",
    "    \"Ciudad Proveedor\":       re.search(r\"Ciudad:\\s*(.+)\", textos.split(\"Proveedor\")[1]).group(1),\n",
    "    \"Total Items\":            re.search(r\"Total Items\\s*[:\\s]*([\\d.,]+)\", textos).group(1),\n",
    "    \"Total Descuento\":        re.search(r\"Total Descuento\\s*:\\s*([\\d.,]+)\", textos).group(1),\n",
    "    \"Sub-Total\":              re.search(r\"Sub-Total\\s*:\\s*([\\d.,]+)\", textos).group(1),\n",
    "    \"IVA\":                    re.search(r\"\\bIVA\\s*:\\s*([\\d.,]+)\", textos).group(1),\n",
    "    \"Impuestos Aplicados\":    re.search(r\"Impuestos Aplicados\\s*:\\s*([\\d.,]+)\", textos).group(1),\n",
    "    \"Total Orden de Compra\":  re.search(r\"TOTAL ORDEN DE COMPRA\\s*:\\s*([\\d.,]+)\", textos).group(1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "651a2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "12ab0390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# diccionario del encabezado\n",
    "encabezado = {\n",
    "    \"Consecutivo\": re.search(r\"Consecutivo\\s*:\\s*(\\d+)\", texto).group(1),\n",
    "    \"Consecutivo BU\": re.search(r\"Consecutivo BU\\s*:\\s*(\\d+)\", texto).group(1),\n",
    "    \"BU\": re.search(r\"BU\\s*:\\s*(\\w+)\", texto).group(1),\n",
    "    \"Fecha\": re.search(r\"Fecha\\s*:\\s*([\\d/]+)\", texto).group(1),\n",
    "    \"Fecha Entrega\": re.search(r\"Fecha Entrega\\s*:\\s*([\\d/]+)\", texto).group(1),\n",
    "    \"Días de Plazo\": int(re.search(r\"Días de Plazo\\s*:\\s*(\\d+)\", texto).group(1)),\n",
    "    \"Forma de Pago\": re.search(r\"Forma de Pago\\s*:\\s*(.+)\", texto).group(1).strip(),\n",
    "    \"Moneda\": re.search(r\"Moneda\\s*:\\s*(.+)\", texto).group(1).strip(),\n",
    "    \"Requisición\": re.search(r\"Requisición\\s*:\\s*(\\d+)\", texto).group(1),\n",
    "    \"Documento Relacionado\": re.search(r\"Doc/Rel\\s*:\\s*(.+)\", texto).group(1).strip(),\n",
    "    \"Estado\": re.search(r\"Estado\\s*:\\s*(.+)\", texto).group(1).strip(),\n",
    "    \"Proveedor\": re.search(r\"Proveedor\\s*:\\s*(.+)\", texto).group(1).strip(),\n",
    "    \"NIT Proveedor\": re.search(r\"Nit\\s*:\\s*(\\d+)\", texto).group(1),\n",
    "    \"Teléfono Proveedor\": re.search(r\"Teléfono\\s*:\\s*(\\d+)\", texto).group(1),\n",
    "    \"Dirección Proveedor\": re.search(r\"Dirección\\s*:\\s*(.+)\", texto).group(1).strip(),\n",
    "    \"Ciudad Proveedor\": re.search(r\"Ciudad:\\s*(.+)\", texto).group(1).strip()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505fb1a0",
   "metadata": {},
   "source": [
    "### Df general - Escoger Columnas -Ordenar dataframe\n",
    "1. Cliente\n",
    "2. Direccion\n",
    "3. Destino\n",
    "4. Numero de Pedido\n",
    "5. Fecha de Orden\n",
    "6. Fecha de Entrega\n",
    "7. Id Falso (Para Cruce de Orden de compra )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "12171e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encabezado = pd.DataFrame([encabezado])\n",
    "df_encabezado  = limpiar_columnas(df_encabezado )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "89df9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a false column\n",
    "df_encabezado['CLIENTE'] = 'ZUANA BEACH RESORT'\n",
    "df_encabezado['DIRECCION'] = df_encabezado['direccion_proveedor']\n",
    "df_encabezado['DESTINO'] = df_encabezado['direccion_proveedor']\n",
    "df_encabezado['NUMERO_DE_PEDIDO'] = df_encabezado['consecutivo']\n",
    "df_encabezado['FECHA_DE_ORDEN'] = df_encabezado['fecha']\n",
    "df_encabezado['FECHA_DE_ENTREGA'] = df_encabezado['fecha_entrega']\n",
    "\n",
    "#Create id False column\n",
    "df_encabezado['id'] =  1\n",
    "\n",
    "#Seleccionar Columnas \n",
    "df_encabezado = df_encabezado[['id', 'CLIENTE', 'DIRECCION', 'DESTINO', 'NUMERO_DE_PEDIDO',\n",
    "                                'FECHA_DE_ORDEN', 'FECHA_DE_ENTREGA']]\n",
    "\n",
    "#SUMAR 8 DIAS A LA FECHA_DE_ENTREGA\n",
    "df_encabezado['FECHA_DE_ENTREGA'] = pd.to_datetime(df_encabezado['FECHA_DE_ENTREGA']) + pd.Timedelta(days=8)\n",
    "\n",
    "#Castear a dia la fecha de la orden\n",
    "df_encabezado['FECHA_DE_ORDEN'] = pd.to_datetime(df_encabezado['FECHA_DE_ORDEN']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f79aadf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CLIENTE</th>\n",
       "      <th>DIRECCION</th>\n",
       "      <th>DESTINO</th>\n",
       "      <th>NUMERO_DE_PEDIDO</th>\n",
       "      <th>FECHA_DE_ORDEN</th>\n",
       "      <th>FECHA_DE_ENTREGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ZUANA BEACH RESORT</td>\n",
       "      <td>CRA 2 NO. 6-80 BELLOHORIZONTE</td>\n",
       "      <td>CRA 2 NO. 6-80 BELLOHORIZONTE</td>\n",
       "      <td>72035</td>\n",
       "      <td>2025-08-03</td>\n",
       "      <td>2025-08-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             CLIENTE                      DIRECCION  \\\n",
       "0   1  ZUANA BEACH RESORT  CRA 2 NO. 6-80 BELLOHORIZONTE   \n",
       "\n",
       "                         DESTINO NUMERO_DE_PEDIDO FECHA_DE_ORDEN  \\\n",
       "0  CRA 2 NO. 6-80 BELLOHORIZONTE            72035     2025-08-03   \n",
       "\n",
       "  FECHA_DE_ENTREGA  \n",
       "0       2025-08-11  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpieza de columnas\n",
    "df_encabezado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e82769",
   "metadata": {},
   "source": [
    "#### Patrones de Producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a3b4c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patron_item = re.compile(\n",
    "    r\"(?P<codigo>\\d{6})\\s+(?P<nombre>[\\w\\s]+)\\s+(?P<presentacion>\\w+)\\s+(?P<cantidad>\\d+)\\s+\"\n",
    "    r\"(?P<valor_unitario>[\\d.,]+)\\s+(?P<dcto>[\\d.]+)\\s+(?P<iva>[\\d.]+)\\s+\"\n",
    "    r\"(?P<total_ico>[\\d.,]+)\\s+(?P<v_unit>[\\d.,]+)\\s+(?P<ico>[\\d.,]+)\"\n",
    ")\n",
    "\n",
    "items = []\n",
    "for match in patron_item.finditer(texto.replace(',', '')):\n",
    "    item = match.groupdict()\n",
    "    # Convertir strings a números\n",
    "    item['cantidad'] = int(item['cantidad'])\n",
    "    for campo in ['valor_unitario', 'dcto', 'iva', 'total_ico', 'v_unit', 'ico']:\n",
    "        item[campo] = float(item[campo])\n",
    "    items.append(item)\n",
    "\n",
    "df_items = pd.DataFrame(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09db0dd",
   "metadata": {},
   "source": [
    "#### Escoger Columnas Productos \n",
    "1. Numero de item\n",
    "2. descripcion\n",
    "3. Cantidad\n",
    "4. Unidad de medida\n",
    "5. Costo Unitario\n",
    "6. importe\n",
    "7. id falso (Unir para realizar insersion de datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "048a250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numero de Item\n",
    "\n",
    "df_items['NUMERO_DE_ITEM'] = df_items['presentacion']\n",
    "df_items['DESCRIPCION'] = df_items['nombre']\n",
    "df_items['CANTIDAD'] = df_items['valor_unitario']\n",
    "df_items['UNIDAD_DE_MEDIDA'] = 'UNIDAD'\n",
    "df_items['COSTO_UNITARIO'] = df_items['ico']\n",
    "df_items['IMPORTE'] = df_items['v_unit']\n",
    "\n",
    "# Escoger Columnas\n",
    "df_items = df_items[['NUMERO_DE_ITEM', 'DESCRIPCION', 'CANTIDAD', 'UNIDAD_DE_MEDIDA',\n",
    "                     'COSTO_UNITARIO', 'IMPORTE']]\n",
    "\n",
    "#Crear el id de la tabla\n",
    "df_items['id'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "62773201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMERO_DE_ITEM</th>\n",
       "      <th>DESCRIPCION</th>\n",
       "      <th>CANTIDAD</th>\n",
       "      <th>UNIDAD_DE_MEDIDA</th>\n",
       "      <th>COSTO_UNITARIO</th>\n",
       "      <th>IMPORTE</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAQX35GR</td>\n",
       "      <td>DON CHICHARRON</td>\n",
       "      <td>192.0</td>\n",
       "      <td>UNIDAD</td>\n",
       "      <td>3166.19</td>\n",
       "      <td>607908.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNDX50GR</td>\n",
       "      <td>ACHIRAS</td>\n",
       "      <td>24.0</td>\n",
       "      <td>UNIDAD</td>\n",
       "      <td>3761.90</td>\n",
       "      <td>90285.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAQX100GR</td>\n",
       "      <td>DON CHICHARRON</td>\n",
       "      <td>100.0</td>\n",
       "      <td>UNIDAD</td>\n",
       "      <td>8565.00</td>\n",
       "      <td>856500.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NUMERO_DE_ITEM     DESCRIPCION  CANTIDAD UNIDAD_DE_MEDIDA  COSTO_UNITARIO  \\\n",
       "0       PAQX35GR  DON CHICHARRON     192.0           UNIDAD         3166.19   \n",
       "1       UNDX50GR         ACHIRAS      24.0           UNIDAD         3761.90   \n",
       "2      PAQX100GR  DON CHICHARRON     100.0           UNIDAD         8565.00   \n",
       "\n",
       "     IMPORTE  id  \n",
       "0  607908.48   1  \n",
       "1   90285.60   1  \n",
       "2  856500.00   1  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d673e5",
   "metadata": {},
   "source": [
    "#### Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1856c365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CLIENTE</th>\n",
       "      <th>DIRECCION</th>\n",
       "      <th>DESTINO</th>\n",
       "      <th>NUMERO_DE_PEDIDO</th>\n",
       "      <th>FECHA_DE_ORDEN</th>\n",
       "      <th>FECHA_DE_ENTREGA</th>\n",
       "      <th>NUMERO_DE_ITEM</th>\n",
       "      <th>DESCRIPCION</th>\n",
       "      <th>CANTIDAD</th>\n",
       "      <th>UNIDAD_DE_MEDIDA</th>\n",
       "      <th>COSTO_UNITARIO</th>\n",
       "      <th>IMPORTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ZUANA BEACH RESORT</td>\n",
       "      <td>CRA 2 NO. 6-80 BELLOHORIZONTE</td>\n",
       "      <td>CRA 2 NO. 6-80 BELLOHORIZONTE</td>\n",
       "      <td>72035</td>\n",
       "      <td>2025-08-03</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>PAQX35GR</td>\n",
       "      <td>DON CHICHARRON</td>\n",
       "      <td>192.0</td>\n",
       "      <td>UNIDAD</td>\n",
       "      <td>3166.19</td>\n",
       "      <td>607908.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ZUANA BEACH RESORT</td>\n",
       "      <td>CRA 2 NO. 6-80 BELLOHORIZONTE</td>\n",
       "      <td>CRA 2 NO. 6-80 BELLOHORIZONTE</td>\n",
       "      <td>72035</td>\n",
       "      <td>2025-08-03</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>UNDX50GR</td>\n",
       "      <td>ACHIRAS</td>\n",
       "      <td>24.0</td>\n",
       "      <td>UNIDAD</td>\n",
       "      <td>3761.90</td>\n",
       "      <td>90285.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ZUANA BEACH RESORT</td>\n",
       "      <td>CRA 2 NO. 6-80 BELLOHORIZONTE</td>\n",
       "      <td>CRA 2 NO. 6-80 BELLOHORIZONTE</td>\n",
       "      <td>72035</td>\n",
       "      <td>2025-08-03</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>PAQX100GR</td>\n",
       "      <td>DON CHICHARRON</td>\n",
       "      <td>100.0</td>\n",
       "      <td>UNIDAD</td>\n",
       "      <td>8565.00</td>\n",
       "      <td>856500.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             CLIENTE                      DIRECCION  \\\n",
       "0   1  ZUANA BEACH RESORT  CRA 2 NO. 6-80 BELLOHORIZONTE   \n",
       "1   1  ZUANA BEACH RESORT  CRA 2 NO. 6-80 BELLOHORIZONTE   \n",
       "2   1  ZUANA BEACH RESORT  CRA 2 NO. 6-80 BELLOHORIZONTE   \n",
       "\n",
       "                         DESTINO NUMERO_DE_PEDIDO FECHA_DE_ORDEN  \\\n",
       "0  CRA 2 NO. 6-80 BELLOHORIZONTE            72035     2025-08-03   \n",
       "1  CRA 2 NO. 6-80 BELLOHORIZONTE            72035     2025-08-03   \n",
       "2  CRA 2 NO. 6-80 BELLOHORIZONTE            72035     2025-08-03   \n",
       "\n",
       "  FECHA_DE_ENTREGA NUMERO_DE_ITEM     DESCRIPCION  CANTIDAD UNIDAD_DE_MEDIDA  \\\n",
       "0       2025-08-11       PAQX35GR  DON CHICHARRON     192.0           UNIDAD   \n",
       "1       2025-08-11       UNDX50GR         ACHIRAS      24.0           UNIDAD   \n",
       "2       2025-08-11      PAQX100GR  DON CHICHARRON     100.0           UNIDAD   \n",
       "\n",
       "   COSTO_UNITARIO    IMPORTE  \n",
       "0         3166.19  607908.48  \n",
       "1         3761.90   90285.60  \n",
       "2         8565.00  856500.00  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join = pd.merge(df_encabezado, df_items, on='id', how='inner')\n",
    "\n",
    "#drop duplicates\n",
    "df_join = df_join.drop_duplicates()\n",
    "df_join "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6afb951",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd8f9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60a51c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee21754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52331b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "79fdc266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valor unidad y total, revisar trocado de valores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "4bdef367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bby ->Tostato\n",
    "#Formatos Llenar manual \n",
    "#DIHEGO\n",
    "#Merkeo\n",
    "#Farmatodo \n",
    "#Panamericana\n",
    "#Alkosto \n",
    "#Sapia -> .zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f054afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bdaf27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85225b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
